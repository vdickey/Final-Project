{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for significant differences in particle grain sizes for different restoration methods on the dunes on Salinas River State Beach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                           Victoria Dickey "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS263"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Outline__\n",
    "1. Introduction\n",
    "1. Methods & Data Sources\n",
    "1. Results\n",
    "1. Conclusions\n",
    "1. Ideas for Future Work\n",
    "1. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Introduction__\n",
    "\n",
    "Here in Monterey, dunes are essential to protecting our low-lying coastal communities and agriculture fields from storms, waves, and erosion. The anatomy of the beach dunes is controlled naturally by the wind and waves. The dunes here in Monterey Bay are blanketed by green and red ice plant which was introduced in the early 1900s to stabilize these naturally changing dunes. Ice plant (Carpobrotus edulis) has shallow roots that form a dense mat, which prevents sand from shifting during wind and storm events. Scientists now think that the sand underneath the ice plant mat erodes and the ice plant mat drops to the new elevation of sand. Native plants associated with the dune habitat have longer root systems that allow dunes to shift around them. It may be important to eradicate ice plant and introduce native plants for the preservation of not only our dunes but also our communities as climate change increases the frequency of storm events. \n",
    "\tThe Central Coast Wetlands Group (https://www.mlml.calstate.edu/ccwg/) here in Moss Landing is currently working on a project to monitor sand loss on the local beach dunes. They have implemented different types of “nourishments” to help accumulate sand naturally. Some nourishments include hay barrels, native plants, and logs. They are doing this project to see if these nourishments help accumulate sand better than what the ice plant was originally thought to achieve. \n",
    "For this project, I preform a one-way ANOVA analysis to see if there is a significant difference in grain size distribution between different nourishment areas: hay barrel, log, native plant. I have log-transformed the data because they are heavily positively skewed from waves and wind (Abuodha, 2003). My one-way ANOVA produces an F-statistic and p-value. After the ANOVA, I also perform a power analysis on the data to understand how many samples I should take in the future to get statistically significant data. I use the log-transformed particle diameter figures to create a visual to compare the grain size distributions among each nourishment and the control samples. \n",
    "\n",
    "__Methods & Data Sources__\n",
    "\n",
    "For this study, I use a Laser Diffraction Particle Size Analyzer to determine the grain sizes of all of the samples. Laser diffraction measures the angular dependence of laser light scattered by an ensemble of particles (López, 2016). With these measurements and the software associated with the Laser Diffraction Particle Size Analyzer, we can log transform the data and understand the grain size distributions and the mean grain sizes for each sample. \n",
    "Samples of sediment were taken on 2-20-2019 at Salinas State River Beach just past the Protrero Road parking lot. For the log nourishment: one sample was taken in front of the log (W1-A) and one sample was taken on the back of the log (W1-B) (Figure 1). For the hay barrel nourishment, 3 samples were taken in the center (HB3-C1, HB3-C2, HB3-C3) in a lateral pattern (Figure 2). For the native plant nourishment, 3 samples were taken, one at each plant (DG1, DG2 and DG3). For a control group, three samples were taken on the dune at the foredune area (Figure 3). After collecting the samples, they were dried and sieved through a sieve with 2 mm openings. Then, the samples were processed through the Laser Diffraction Particle Size Analyzer (LS 13 320). For each sample, preliminary statistics have been calculated using the LS software associated with the Laser Diffraction Particle Size Analyzer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1\n",
    "![alt text](overlay_W1-A,W1-B.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2\n",
    "![alt text](overlay_HB-2A,HB-2B,HB-2c.png  \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3\n",
    "![alt text](overlay_DG-1,DG-2,DG-3.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4\n",
    "![alt text](overlay_dunes.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Log      Hay       NP     Dune\n",
      "0  427.536  454.036  491.275  506.030\n",
      "1  461.572  493.498  466.368  369.939\n",
      "2      NaN  520.387  557.441  374.606\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "import pandas as pd\n",
    "\n",
    "mean_data = pd.read_csv ('Mean_Data.csv')\n",
    "print (mean_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    427.536\n",
       "1    461.572\n",
       "Name: Log, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = np.isfinite(mean_data['Log'])\n",
    "mean_data['Log'][fi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7476672763506207 0.2442405688607124\n"
     ]
    }
   ],
   "source": [
    "F,p = stats.f_oneway(mean_data['Log'][fi],mean_data['Hay'], mean_data['NP'], mean_data['Dune'])\n",
    "print (F,p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We fail to reject the null hypothesis and do not have to complete a Post-Hoc Test\n"
     ]
    }
   ],
   "source": [
    "if p < .05:\n",
    "    print('We reject the null hypothesis')\n",
    "else: \n",
    "    print('We fail to reject the null hypothesis and do not have to complete a Post-Hoc Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from statsmodels.stats import power as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.153892778205668\n"
     ]
    }
   ],
   "source": [
    "#Anova Power Test\n",
    "samplenumber = p.FTestAnovaPower().solve_power(effect_size=2.6,nobs=None,alpha=0.05,power=0.8)\n",
    "print(samplenumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusions__\n",
    "\n",
    "To visualize the differences in the overall spread in the particle sizes between each sample, I use the Laser Diffraction Particle Size Analyzer software to create overlay figures for each group of samples (figures 1-4). In these figures, we can see that the overall spread of the particle sizes do not differ much between each sample. Unfortunately, this software does not calculate overlays of more than 7 samples, so I cannot visualize if there are significant differences in particle sizes between sample groups. In order to find out if there is any statistically significant differences between the sample groups, I preform a hypothesis test for statistical significance.\n",
    "\n",
    "In this study, I use a one-way ANOVA test for the statistical hypothesis test because I am making observations about the differences in the means of the particle sizes of the samples. The null hypothesis in a one-way ANOVA test is that there is no difference between the means of two populations. One of the ways I can interpret the results of this test is to use the p-value output, which is the probability of observing the result given that the null hypothesis is true. When interpreting this value, I set the significance level to be 0.05. The result of my significance test is “statistically significant” if my p-value is less than the significance level of 0.05, meaning the null hypothesis is rejected. The p-value that I get when I run my ANOVA test is 0.244. This value is greater than my significance level so I fail to reject my null hypothesis. This can help me conclude that the mean values are not statistically significantly different between each sample. \n",
    "Another output of the one-way ANOVA is the F-statistic, which is a ratio of the variation between sample means and the variation within the samples. This ratio is expected to be roughly equal under the null hypothesis, which produces an F-statistic of approximately 1.  In order to reject the null hypothesis that the group means are equal, we need a high F-value. When I preform the one-way ANOVA, my F-statistic is 1.747, meaning the group means are close together (low variability) relative to the variability within each group. This low F-statistic also supports the decision to fail to reject the null hypothesis.\n",
    "\n",
    "If the differences in the means were statistically significant, and I were to reject the null hypothesis, I would then preform a Post-Hoc test, like a Tukey Honest Significant Difference test which allows us to see the specific differences in the means. The ANOVA test will tell me if there are any significant differences in the means and the Tukey HSD test will tell me where those significant differences are. Because I did not find any significant difference in the means between my groups and I failed to reject my null hypothesis, I did not carry out a Post-Hoc test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ideas for Future Work__\n",
    "\n",
    "To understand why I did not find statistically significant differences in the means between my sample groups, I can collect more samples in the future. In order to calculate exactly how many samples are needed to potentially produce statistically significant results for an ANOVA test, I conduct a Power Analysis. The Power Analysis usually calculates the statistical power that the test correctly rejects the null hypothesis. If I set that statistical power to the commonly used 80% (a high statistical power), I can calculate how many samples I would need to collect. I preformed the power analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__References__\n",
    "\n",
    "Abuodha, J.O.Z. \"Grain size distribution and composition of modern dune and beach sediments, Malindi Bay coast, Kenya.\" Journal of African Earth Sciences (2003): 41-54. web.\n",
    "\n",
    "Chou, L.M, J.Y Yu and T.L Loh. \"Impacts of sedimentation on soft-bottom benthic communities in the southern islands of Singapore.\" Hydrobiologia (2004): 91-106. web.\n",
    "\n",
    "López, Gloria. \"Grain Size Analysis.\" Gilbert, Allan S. Encyclopedia of Geoarchaeology. Springer, 2016. web.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
